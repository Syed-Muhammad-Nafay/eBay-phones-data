# ğŸ“± eBay Flagship Phone Scraper & Cleaner

This project is a complete pipeline for **scraping**, **storing**, and **cleaning** pricing data of flagship iPhones from eBay. 

The scraper was initially written manually and later optimized with AI to behave more like a human and reduce the risk of detection.

---

## ğŸš€ Features

### ğŸ•µï¸ Human-like Stealth Web Scraper
- Scraper mimics human browsing behavior using:
  - `curl_cffi` for lightweight requests
  - `nodriver` as a fallback headless browser
  - Randomized user agents with `fake_useragent`
  - Random delays, scrolling, and page loads
- Searches for various phone models across different item conditions and pages

### ğŸ—ƒï¸ PostgreSQL Integration
- Data is saved directly into a local PostgreSQL database using a custom function `add_a_record()`
- This ensures structured and consistent storage before any processing

### ğŸ§¹ Data Cleaning
- Exported raw data (`products.csv`) is cleaned and transformed into `clean_phones.csv`
- Cleaning steps include:
  - Extracting model names from messy eBay titles using regex
  - Standardizing prices, shipping, and location data
  - Fixing inconsistent formatting and removing irrelevant records

---

## ğŸ“ Project Structure
ğŸ“¦ Ebay_FLAGSHIP_Project/<br>
â”œâ”€â”€ .venv/ # Virtual environment (excluded via .gitignore)<br>
â”œâ”€â”€ pycache/ # Python cache files<br>
â”œâ”€â”€ .ipynb_checkpoints/ # Jupyter auto-saves<br>
â”œâ”€â”€ latest_logs/ # Optional logging<br>
â”œâ”€â”€ cleaning_scrapped_data.ipynb # Notebook for data cleaning<br>
â”œâ”€â”€ clean_phones.csv # Final cleaned dataset<br>
â”œâ”€â”€ products.csv # Raw scraped dataset from PostgreSQL<br>
â”œâ”€â”€ database.py # PostgreSQL setup and insert logic<br>
â”œâ”€â”€ test_webscrapper_for_Ebay.py # Initial or testing scraper<br>
â”œâ”€â”€ libraries_requirment.txt # Required dependencies<br>
â”œâ”€â”€ .gitignore<br>
â”œâ”€â”€ README.md<br>


---

## ğŸ“Š Data Analysis

ğŸš§ **Data analysis is in progress** â€” but you are welcome to explore `clean_phones.csv` and draw your own insights! The data is cleaned, structured, and ready for use.

---

## ğŸ“¦ Requirements

Install dependencies using:

```bash
pip install -r libraries_requirment.txt

